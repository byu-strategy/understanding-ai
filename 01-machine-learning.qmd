---
title: "Machine Learning"
---

::: under-construction-banner
<img src="images/under-construction.png" alt="Course Under Construction" class="under-construction-image"/>
:::

```{=html}
<style>
.under-construction-banner {
  background-color: #e0e0e0;  /* Light grey background */
  padding: 1rem 1rem;         /* Makes the banner tall */
  text-align: center;
}

.under-construction-image {
  max-width: 250px;           /* Shrinks the image */
  width: 100%;
  height: auto;
  margin: 0 auto;
  border-radius: 8px;
  box-shadow: 2px 2px 8px rgba(0,0,0,0.15);
}
</style>
```

![Image source: *Build a Large Language Model (From Scratch)* by Sebastian Raschka](images/ai-ml-map.png){width="70%" fig-align="center"}

## Machine Learning in a Nutshell

Machine learning is about enabling computers to recognize patterns in data so they can make accurate predictions or decisions without being explicitly programmed for every scenario. At its core, it involves feeding a model real-world examples encoded in a dataset and allowing the computer to learn the relationship between inputs and outputs. Once trained, the model can apply that learned relationship to make predictions on new, unseen data.

To build a machine learning model, we need four key ingredients:

1.  **A mathematical model:** This defines the form of the mathematical function we’ll use to relate inputs to outputs, for example, a straight line (linear) or a more flexible structure like a neural network (non-linear).

::: {.callout-tip collapse="true" collapsed="true"}
## What do we mean by "linear"?

"Linear" in this context means that the effect of $x$ on $\hat{y}$ is **proportional and constant**: no matter what value of $x$ we choose, an increase of 1 unit in $x$ always increases $\hat{y}$ by exactly $w_1$ units. This property makes the model highly interpretable.
:::

2.  **Training data:** A collection of real-world examples that pair inputs with their corresponding outputs. The quality and relevance of this data are crucial to how well the model can learn and make accurate predictions.
3.  **A loss function:** A mathematical expression that measures how far off the model’s predictions are from the correct answers. It provides feedback to help the model improve over time.
4.  **A training algorithm:** A step-by-step procedure that combines the first three ingredients in a way that minimizes the prediction errors produced by the model. This is where the so-called *learning* takes place.

So what exactly is being *learned*? The computer is *learning* the *weights* (parameters) of the chosen model. This is best understood through an example. We’ll start with the simplest possible machine learning model: simple linear regression. It’s a powerful tool that helps us understand the core ideas behind more complex models, including the ones that power today’s cutting-edge AI systems like ChatGPT.

## Simple Linear Regression

### 1st Ingredient: Mathematical model

A simple linear regression model takes a single **input variable** $x$ and predicts the value of a corresponding **output variable** $y$. For example, the input variable might represent a house's *square footage*, and the output variable could represent the *value* of the home.

We can write down the relationship between *square footage* and *value* in the form of a mathematical equation (also called a mathematical *function* or a *model*):

$$
y = w_0 + w_1 x
$$

Where $y$ represents the home *value* and $x$ represents the *square footage*.

In machine learning jargon $w_0$ and $w_1$ are called the **parameters** or **weights** of the model (hence the use of $w$ in the notation) and describe the nature of the relationship between $x$ and $y$. $w_0$ and $w_1$ are the numbers that the computer will *learn* (i.e. derive) based on what is observed in real life which will be encoded into *training data* discussed in the next section.

In other fields such as econometrics these might be introduced using the greek alphabet notation of $\alpha$ and $\beta$.

You might recognize this equation as the equation for a line in *slope-intercept* from which is often presented as:

$$
y = mx + b
$$

where $x$ and $y$ are numbers in the coordinate plane with $m$ representing the slope of the line and $b$ representing the y-intercept (the point where the line crosses the y-axis) as shown in the image below:

![](images/line-graph.png){width="70%" fig-align="center"}

Simple linear regression and the equation of a line are in fact the same mathematical equation. In the context of linear regression, we simply use different notation: $w_1 = m$ (the slope), and $w_0 = b$ (the y-intercept which in machine learning is referred to as the *bias* term).

It's common for different fields of study to use different notation and words for the same mathematical concepts. Unfortunately this can be one of the biggest sources of confusion for students so we will make an effort to call out these differences throughout the course.

Now that we've shown that simple linear regression is actually just the equation of a line where $w_0$ is the y-intercept and $w_1$ is the slope we can have a visual picture in mind for how an input variable $x$ and the output variable $y$ are related.

::: {#fig-slr-line layout-ncol="1"}
![**Simple Linear Regression Line**](images/slr-line.png){width="70%"}
:::

::: {.callout-tip collapse="true" collapsed="true"}
## Intuition check

Think about our home value example, where we're predicting a house's price based on its square footage.

-   What does your intuition tell you about the values $w_0$ and $w_1$ are likely to take on once they are estimated?

-   Do you expect them to be positive or negative numbers?

-   Assume $x$ was $0$, what would the equation be telling you?
:::

As soon as we come up with values for $w_0$ and $w_1$ have a way predicting values of $y$ when plugging in any value of $x$ to the fitted equation.

The goal of machine learning is to *learn* the best possible values $w_0$ and $w_1$ allowing us to make good predictions of a homes *value* based on it's *square footage*. We will soon explore how the computer learns these weight values but to build our intuiton on what the model does we can start by simply guessing values for the weights. For example, let's assume:

$$
w_0 = 50,\!000 \quad \text{and} \quad w_1 = 200
$$

Then our function becomes:

$$
\hat{y} = 50,\!000 + 200x
$$

We use the notation $\hat{y}$ (read as “y-hat”) here to emphasize that this is a now predicted value based on the model, not an observed or actual value.

This act of using the trained model to compute a prediction based on an input $x$ is also called **inference** since we are *inferring* an estimated output $\hat{y}$.

Using this model we can predict that a home with 3,000 square feet will have a value of:

$$
\hat{y} = 50,\!000 + 200 \cdot 3,\!000 = \$650,\!000
$$

Now, consider what the model predicts for a home with 0 square feet:

$$
\hat{y} = 50,\!000 + 200 \cdot 0 = \$50,\!000
$$

This implies that the base value of the property—the land alone, with no house—might be interpreted as \$50,000. This is exactly why both $w_0$ and $w_1$ are necessary. If we had included only $w_1 x$ and omitted $w_0$, the model would always predict 0 for an input of $x = 0$, which might not reflect the reality (e.g., land still has value).

In machine learning, the term **bias** is used to refer to this $w_0$ value. The name comes from the fact that it shifts (or “biases”) the entire output of the model up or down, independent of the input. Geometrically, it determines the $y$-intercept of the prediction line. It allows the model to better fit real-world data.

Choosing a different set of weight values would result in a different equation, resulting in a different prediction. For example, assume instead that $w_0 = 25,000$ and $w_1 = 300$ resulting in the following equation:

$$
\hat{y} = 25,000 + 300 x
$$

This model would predict that the same 3,000 square-foot home has a much higher value of $\$925,000 = 25,000+300*3,000$.

Let's assume the \$3,000 square foot home we have in mind recently sold for \$800,000 reflecting it's true value (a single instance of $y$). We could then compute the error associated with each set of model weights as the absolute value of the prediction error as follows:

1.  Prediction error when $w_0 = 50,\!000$ and $w_1 = 200$: $\left| 650,000 - 8000000 \right| = 150,000$
2.  Prediction error when $w_0 = 25,\!000$ and $w_1 = 300$: $\left| 925,000 - 8000000 \right| = 125,000$

Given these results we might reasonably conclude that the second set of model weights produced the better prediction, since it was less wrong by \$25,000.

In machine learning this prediction error is commonly called the model's *loss,* that is, how far off the prediction is from the observed truth. The mathematical function by which we compute prediction error is called the *loss function*. In our case, we could represent our choice of loss function as $\left| \hat{y} - y \right|$.

There are many possible choices of loss function. For example, we didn't have to use absolute value, we could have simply taken the difference as our measurement of loss. We will discuss loss functions and introduce the most commonly used loss functions in later sections.

### 2nd Ingredient: Training Data

In order for a computer to *learn* the best weight values for a model, we need to communicate with it in the language it understands: **data**. In this context, “data” refers to numerical values organized in rows and columns, like a spreadsheet or matrix. Each row is a single **example**, and each column holds a particular **feature** or **label**.

For our home value prediction example, imagine a simple dataset with two columns:

-   One column for the **square footage** of a home (the *input*), and\
-   One column for the **value** of the home (the *output*).

Each row contains both the square footage and the corresponding value for a particular house. Together, each pair of values forms what we call an **input-output pair**. A complete set of these pairs is called a **dataset**.

We can write this dataset using the following compact mathematical notation:

$$
\{(x^{(i)}, y^{(i)})\}_{i=1}^n
$$

This might look intimidating at first, but it’s just a convenient way of saying:

> “We have $n$ examples. For each example $i$, we observe an input $x^{(i)}$ and a corresponding output $y^{(i)}$.”

Let’s break down the notation a bit further:

-   The curly braces $\{ \}$ mean we’re describing a set, a collection of items.
-   The superscript $(i)$ just means “for example number $i$”
-   Each item in the set is a pair: $(x^{(i)}, y^{(i)})$ where:
    -   $x^{(i)}$ is the input (e.g., square footage) for the $i$th example
    -   $y^{(i)}$ is the output (e.g., home value) for that same example
-   The subscript $_{i=1}^n$ tells us there are $n$ examples and we are referring to all $1$ to $n$ of them.

If you wrote this out as a table, it might look like this:

| Example ($i$) | $x^{(i)}$ = Square Footage | $y^{(i)}$ = Home Value |
|---------------|----------------------------|------------------------|
| 1             | 1200                       | 250,000                |
| 2             | 1400                       | 275,000                |
| 3             | 1600                       | 300,000                |
| ...           | ...                        | ...                    |
| $n$           | (last example)             |                        |

This is the kind of data we use to “train” a machine learning model, by showing it many examples, we give it a chance to learn the relationship between inputs and outputs.

::: {.callout-tip collapse="true" collapsed="true"}
### Terminology: Inputs and Outputs

In different fields and contexts, we often use different terms for the same underlying ideas. Here's a helpful reference for the various names used for **inputs** and **outputs** in machine learning and related areas:

| Concept | Common Synonyms | Notes |
|----|----|----|
| **Input** | Feature, Independent Variable, Predictor, Covariate, Regressor, $x$ | The value(s) we feed into the model to make a prediction. Can be one variable or many. |
| **Output** | Label, Target, Dependent Variable, Response, $y$ | The value the model is trying to predict or learn from. |
| **Input-Output Pair** | Example, Observation, Data Point, $(x^{(i)}, y^{(i)})$ | A single row of data showing both the input and the correct output. |
| **Collection of Examples** | Dataset, Training Data, Sample | All the input-output pairs we give to the model to learn from. |
| **Predicted Output** | Prediction, Estimate, $\hat{y}$ | The output the model thinks is correct, based on what it learned. |
:::

There are actually four equivalent ways of representing a dataset, each useful in different contexts. You will be greatly aided in your study of machine learning if you can recognize and switch between all four forms with ease. Different textbooks, courses, tutorials and code libraries will use different representations so developing fluency in all of them will help you understand ideas more deeply and communicate more clearly.

1.  **Mathematical Set Notation:**\
    This is the notation we just introduced:\
    $$
    \{(x^{(i)}, y^{(i)})\}_{i=1}^n
    $$

It represents the dataset as a collection of $n$ input-output pairs, where each $x^{(i)}$ is an input and each $y^{(i)}$ is the corresponding output. This form is widely used in textbooks and research papers because of its compactness and precision. It’s the language of mathematics, and it's especially helpful when trying to understand what’s happening *under the hood* as computer code executes. By using this notation, we can reason more clearly about how models learn and make predictions.

2.  **Spreadsheet or Table Format:**\
    This is the most familiar form for most people and is often used in business and statistics. Each row represents an example; each column represents a variable or feature.

    | Example ($i$) | $x^{(i)}$ = Input (e.g., SqFt) | $y^{(i)}$ = Output (e.g., Price) |
    |----|----|----|
    | 1 | 1200 | 250,000 |
    | 2 | 1400 | 275,000 |
    | 3 | 1600 | 300,000 |
    | ... | ... | ... |
    | $n$ | — | — |

    This is also the format used in tools like Excel, Google Sheets, or data frames in Python and R.

3.  **Mathematical Matrix Notation:**\
    Matrix notation is a compact and powerful mathematical way to represent an entire dataset, especially when trying to understand what calculations the computer is making while executing machine learning algorithms (discussed in the next section). In matrix form:

-   The **inputs** are stored in a matrix called $X$, with $n$ rows (one for each example) and $d$ columns (one for each feature or input variable).
-   The **outputs** are stored in a column vector called $y$, with $n$ rows (one for each label or true value).

If each input has just one feature (like square footage), then $X$ is simply a single column of numbers (a vector). But if we have **more than one input feature**, for example, both square footage and number of bedrooms, then $X$ becomes a matrix with multiple columns, like this:

$$
X =
\begin{bmatrix}
x_1^{(1)} & x_2^{(1)} \\
x_1^{(2)} & x_2^{(2)} \\
\vdots & \vdots \\
x_1^{(n)} & x_2^{(n)}
\end{bmatrix}
$$

Here:

-   Each **row** represents one house (one example from the dataset).
-   Each **column** represents a feature:
    -   $x_1^{(i)}$ might be the square footage of house $i$
    -   $x_2^{(i)}$ might be the number of bedrooms in house $i$

This structure easily extends to more features. For example, if we also include number of bathrooms, year built, and lot size, then $X$ would have 5 columns total (one for each feature).

The output vector $y$ stays the same regardless of the number of inputs with one value per row, like the price of the home:

$$
y =
\begin{bmatrix}
y^{(1)} \\
y^{(2)} \\
\vdots \\
y^{(n)}
\end{bmatrix}
$$

> Matrix notation lets us express model computations in a **compact, efficient** form that computers can execute quickly.
>
> It will be essential when we **scale up** to more than one input feature. It illustrates how a machine *thinks.* It’s ideal for: - Handling **many examples and features** - Performing **vectorized calculations** like dot products and gradients - Writing models in **clean, code-friendly format**
>
> Matrix notation makes your reasoning and implementation **faster, clearer, and more powerful**. We'll use it throughout the course.

4.  **Code Representation (Arrays or Tensors):**\
    When implementing models in code, we typically use arrays (Python's NumPy package) or tensors (Python's PyTorch package) which are data structures that store values in memory for numerical computation.

    Below is an example with NumPy

```{python}
# NumPy
import numpy as np
X = np.array([[1200], [1400], [1600]])
y = np.array([[250000], [275000], [300000]])
print("X =", X)
print("y = ", y)
```

So what does this mean?

-   `X` is a **matrix of inputs** (in this case, just one feature: square footage).\
    Each **row** represents one example:
    -   1200 square feet\
    -   1400 square feet\
    -   1600 square feet
-   `y` is a **vector of outputs** (the target values, like home prices).\
    Each row in `y` matches the corresponding row in `X`.

Let's now connect this code back to the set and matrix representations of a dataset.

**Equivalence with Set Notation**

In set notation this tiny dataset could be represented as three input-output pairs:

$$
\{(x^{(i)}, y^{(i)})\}_{i=1}^3
$$ More specifically:

-   $x^{(1)} = 1200$, $y^{(1)} = 250{,}000$\
-   $x^{(2)} = 1400$, $y^{(2)} = 275{,}000$\
-   $x^{(3)} = 1600$, $y^{(3)} = 300{,}000$

Each pair $(x^{(i)}, y^{(i)})$ is represented by a row in `X` and the corresponding row in `y`.

**Equivalence with Matrix Notation**

We can also see how this toy dataset would be written in matrix notation as a pair of matrices, one for the inputs and one for the outputs:

$$
X =
\begin{bmatrix}
x_1^{(1)} \\
x_1^{(2)} \\
x_1^{(3)}
\end{bmatrix}
=
\begin{bmatrix}
1200 \\
1400 \\
1600
\end{bmatrix},
\quad
y =
\begin{bmatrix}
y^{(1)} \\
y^{(2)} \\
y^{(3)}
\end{bmatrix}
=
\begin{bmatrix}
250{,}000 \\
275{,}000 \\
300{,}000
\end{bmatrix}
$$

-   $X$ is an $n \times 1$ input matrix (with one feature per example),
-   $y$ is an $n \times 1$ output vector (with one label per example).

PyTorch Example

Lastly, below we represent the same toy dataset using **PyTorch**, currently the most popular deep learning library, and the one used to develop many modern large language models (LLMs).

PyTorch uses a data structure called a **tensor**.

A **tensor** is a generalization of familiar objects like scalars, vectors, and matrices:

-   A **scalar** is a 0-dimensional tensor (e.g., `5`)
-   A **vector** is a 1-dimensional tensor (e.g., `[1200, 1400, 1600]`)
-   A **matrix** is a 2-dimensional tensor (e.g., a table of numbers)
-   A **3D tensor** is a collection or stack of matrices. You can think of it as a book of matrices, where each page is a 2D grid (matrix), and the whole book has depth (i.e., the number of pages)
-   A **4D tensor** is a collection of 3D tensors. You can think of it as a **library of books**, where:
    -   Each **book** is a 3D tensor (a stack of matrices),
    -   Each **page** in a book is a matrix,
    -   And each matrix contains rows and columns of numbers.

Increasing the tensor dimension allows us to compactly describe multiple sets of structured data and for a computer to perform parallel computations efficiently which is essential when training modern LLMs.

In theory, there is no limit on the number of dimensions a tensor can have.

In practice, we won't need more than 4D tensors to build modern large language models (LLMs).

For simple models like linear regression, a 2D tensor (i.e., a matrix) is sufficient to represent the data.

Below we illustrate the same toy data set using a PyTorch tensor.

```{python}
import torch

# Input data: square footage (in one column)
X = torch.tensor([[1200.], [1400.], [1600.]])

# Output data: home prices
y = torch.tensor([[250000.], [275000.], [300000.]])

print("X (inputs):")
print(X)

print("\ny (outputs):")
print(y)
```

The dot (.) at the end of the numbers (like 1200. or 250000.) indicates that the numbers are being treated as floating point numbers (i.e., float type) rather than integers. A floating point number is a number that can represent decimal values on a computer, in contrast to an integer, which can only represent whole numbers. PyTorch models expect inputs and outputs to be floating point numbers because most model operations involve decimals.

We will soon use a set of training Data to help learn model parameters but before doing so we need to introduce the remaining two ingredients for machine learning: loss functions and training algorithms.

### 3rd Ingredient: Loss Function

A *loss function* is separate mathematical equation whose purpose it to quantify the error between a model’s predictions $\hat{y}^{(i)}$ and the true output values observed in the training data $y^{(i)}$. When discussing mathematical model structure (i.e. simple linear regression), we briefly introduced the notion of a loss function and used the absolute value of the difference between $\hat{y}^{(i)}$ and between and $y^{(i)}$ to measure prediction error (i.e. loss): $\left| \hat{y} - y \right|$. Note that this *loss* is calculated for each individual training example. That is, if we had 100 training examples (i.e. rows of data) containing the square footage and home value for 100 homes, we could compute the *loss* for each of these examples. The dotted lines in the plot below help you visualize the loss for each example in a set of training data.

![](images/slr-loss.png){width="70%" fig-align="center"}

We could then find the average loss by summing up the observation level loss and dividing by the number of observations to get what is commonly called **Mean Absolute Error (MAE)**, written as:

$$
\frac{1}{n} \sum_{i=1}^{n} \left| \hat{y}^{(i)} - y^{(i)} \right|
$$

MAE is an intuitive choice for a loss function, but not the only choice. There are other equations that will measure prediction error in slightly different ways. One such equation and the most commonly used loss function when learning parameters for a simple linear regression is called **Mean Squared Error (MSE)**, written as:

$$
\frac{1}{n} \sum_{i=1}^{n} \left( \hat{y}^{(i)} - y^{(i)} \right)^2
$$

Recall that $\hat{y} = w_0 + w_1 x$ hence we can plug $w_0 + w_1 x$ into the equation for $\hat{y}$ to make clear that the loss function, which we denote as $\mathcal{L}$ (a stylized version of the capital Latin letter L), is a function of two variables: $w_0$ and $w_1$. This means that different values of $w_0$ or $w_1$ or both will yield different loss values. The goal of machine learning is to find (i.e. *learn*) the values of $w_0$ and $w_1$ that will make this loss function (i.e., total prediction error) as small as possible.

$$
\mathcal{L}(w_0, w_1) = \frac{1}{n} \sum_{i=1}^n (\hat{y}^{(i)} - y^{(i)})^2 = \frac{1}{n} \sum_{i=1}^n (w_0 + w_1 x^{(i)} - y^{(i)})^2 
$$

In the next section, we will introduce a training algorithm called **gradient descent**. This algorithm systematically searches through different combinations of values for $w_0$ and $w_1$ to find those that *minimize the loss* or in other words, to *learn* the best-fitting line.

To really understand how gradient descent works, we first need to deepen our understanding of the **loss function**, specifically how it behaves with respect to the parameters $w_0$ and $w_1$.

Recall that in simple linear regression, we model predictions as:

$$
\hat{y} = w_0 + w_1 x
$$

When we think of this as a function of the input variable $x$, we can plot it as a straight line on a 2D coordinate system (with $x$ on the horizontal axis and $\hat{y}$ on the vertical axis) as we did earlier.

But now, let’s flip our perspective. In the previous section, we learned that **training data** consists of actual examples, pairs of $x$ and $y$, from the real world. So once we have a training dataset, $x$ and $y$ are *known*. That means we no longer need to treat $x$ as a variable in our model equation.

In this case, the prediction formula:

$$
\hat{y} = w_0 + w_1 x
$$

becomes a function where $w_0$ and $w_1$ are the unknown variables. Our goal is to adjust these weights to reduce the difference between our predicted values $\hat{y}$ and the actual outcomes $y$. So during model training, we treat $w_0$ and $w_1$ as the variables to solve for, which turns our **loss function** into a function of two variables, $w_0$ and $w_1$:

$$
\mathcal{L}(w_0, w_1) = \frac{1}{n} \sum_{i=1}^n (\hat{y}^{(i)} - y^{(i)})^2 = \frac{1}{n} \sum_{i=1}^n (w_0 + w_1 x^{(i)} - y^{(i)})^2 
$$ Don’t be intimidated by the notation. Once we have a training dataset, all the $x^{(i)}$ and $y^{(i)}$ values are known values. The only unknowns we are solving for are $w_0$ and $w_1$.

::: {.callout-tip collapse="true" collapsed="true"}
## Unpacking the notation of the MSE Loss Function

This is called the Mean Squared Error (MSE) loss function, and it helps us measure how good or bad our model’s predictions are.

The big curly $\mathcal{L}$ is a stylized version of the capital Latin letter L. In this context, $\mathcal{L}$ stands for “Loss” or sometimes “Loss function."

-   $w_0$ and $w_1$ are the parameters (or weights) of our simple linear regression model. Notice that they are playing the roles of unknown variables in this notation: $\mathcal{L}(w_0, w_1)$. This is because we don't know what these values are or should be yet, that's what we want the computer *learn* for us.
-   $x^{(i)}$ is the input (e.g., square footage of a house)
-   $\hat{y}^{(i)} = w_0 + w_1 x^{(i)}$ is the model’s predicted output (e.g., the predicted house price).
-   $y^{(i)}$ is the true value (the actual house price for data point $i$).
-   $(\hat{y}^{(i)} - y^{(i)})^2$ is the squared error: how far off the prediction is, squared to make sure it’s always positive and to penalize big mistakes more than small ones.
-   $\sum_{i=1}^n$ adds up the squared errors for all $n$ data points in our dataset (the Greek letter $\sum$ is called "capital sigma" and means we should "add up a bunch of terms")
-   $\frac{1}{n}$ takes the average of all those squared error terms.

This function tells us how well our model is performing overall. A smaller value means our predictions on average are close to the true values, and a larger value means on average we’re making bigger mistakes.

Our goal is to find the values of $w_0$ and $w_1$ that make this loss function as small as possible.
:::

Because the loss depends on *both* $w_0$ and $w_1$, we need **three dimensions** to visualize and plot this function:

-   One axis for $w_0$\
-   One axis for $w_1$\
-   A vertical axis for the loss value $\mathcal{L}$ (often labeled the $z$-axis in other contexts)

As the saying goes, *a picture is worth a thousand words*, so let’s visualize what this looks like.

In the plot below, we graph the loss function $\mathcal{L}(w_0, w_1)$ to see it as a 3D surface, with $w_0$ on the x-axis, $w_1$ on the y-axis, and the height of the surface representing the mean squared error loss $\mathcal{L}$. This gives us a *landscape* of possible values of $w_0$ and $w_1$ to choose from.

{{< include assets/01-machine-learning/bowl_surface_plot.qmd >}}

As can be seen from the plot, there are many possible choices of $w_0$ and $w_1$, each resulting in a different loss value. In the next section, we will study a foundational algorithm called gradient descent which is designed to intelligently and iteratively explore different combinations of $w_0$ and $w_1$, calculating the loss that results from each combination. The process continues until **convergence** occurs, that is, until the algorithm believes it has found the best choice of weights that minimize the loss. We’ll explore the details of how gradient descent works in the next section.

::: {.callout-tip collapse="true" collapsed="true"}
## Intuition Check

Which choice of weight values is better: point A or point B? Why?
:::

::: {.callout-tip collapse="true" collapsed="true"}
## Why use MSE for the loss function?

MSE is the most commonly used loss function for regression problems because it has several useful properties:

-   **Smooth and differentiable**: The squaring operation makes the MSE function smooth and continuous, which is important for optimization methods like gradient descent that rely on computing derivatives. (discussed in the next section)
-   **Penalizes large errors**: By squaring the difference between prediction and truth, MSE emphasizes larger errors more than smaller ones. This is often desirable when big mistakes are especially costly.
-   **Unique minimum**: For linear models, the MSE loss function is convex (it's bowl shaped), meaning it has a single global minimum. This makes optimization straightforward and ensures reliable convergence during training.

These properties make MSE both practical and theoretically sound for training models to make accurate predictions.
:::

### 4th Ingredient: Training Algorithm

Once we have selected a loss function, our next task is to find the values of $w_0$ and $w_1$ that minimize it. But how do we actually do that?

Imagine you’re hiking on the inside of bowl-shaped surface of the loss function plot we explored in the previous section. Where you are standing corresponds to a specific combination of $w_0$ and $w_1$. Your goal is to get to the lowest possible point on the surface, the bottom of the bowl, where the loss is minimized and the model makes the best possible predictions.

The training algorithm called **gradient descent** helps you do exactly that in a very clever and efficient way.

Before taking the next step down the hill, it asks:

> “Which direction should I go to decrease the loss most quickly? Or equivalently, which direction is the steepest and will get me to the bottom of this bowl as fast as possible.”

To answer that question, gradient descent uses a mathematical tool called the **gradient**, just a fancy word for the direction of *steepest ascent* (what we’d call the **slope** in calculus). Since we want to go downhill, toward lower loss, we will actually move in the opposite (i.e. negative) direction of the gradient.

Since we are working with a loss function of two variables, $\mathcal{L}(w_0, w_1)$, there are two different directions in play for each step we take down the hill. Hence, in this case, the **gradient** will be a vector with two components, one representing each direction (you can think of each component as the the "slope" in a certain direction):

-   $\frac{\partial \mathcal{L}}{\partial w_0}$: how the loss changes when we adjust $w_0$
-   $\frac{\partial \mathcal{L}}{\partial w_1}$: how the loss changes when we adjust $w_1$

These are called the **partial derivatives** of the function. They measure how sensitive the loss is to each parameter. They tell us the function's rate of change as we vary **one parameter at a time**, holding the others constant.

We represent the gradient vector in the following mathematical notation:

$$
\nabla \mathcal{L}(w_0, w_1) =
\begin{bmatrix}
\frac{\partial \mathcal{L}}{\partial w_0} \\
\frac{\partial \mathcal{L}}{\partial w_1}
\end{bmatrix}
$$

::: {.callout-tip collapse="true" collapsed="true" title="Understanding the Gradient Notation"}
The expressions

$$
\frac{\partial \mathcal{L}}{\partial w_0} \quad \text{and} \quad \frac{\partial \mathcal{L}}{\partial w_1}
$$

are called **partial derivatives**. They measure how sensitive the loss is to each parameter, essentially, how steep the slope is along each direction of the surface plot.

Here's what the notation means:

-   The **partial derivative symbol** $\partial$ (pronounced *“partial”*) means we’re measuring the rate of change with respect to just **one** variable, keeping the others constant.
-   $\mathcal{L}$ (script L) represents the **loss function**, which tells us how far off our model’s predictions are from the actual outcomes.
-   $w_0$ and $w_1$ are the **parameters** of our model.

So:

-   $\frac{\partial \mathcal{L}}{\partial w_0}$ tells us how the loss changes if we slightly increase $w_0$, holding $w_1$ fixed.
-   $\frac{\partial \mathcal{L}}{\partial w_1}$ tells us how the loss changes with respect to $w_1$, keeping $w_0$ fixed.

Together, these two values form the **gradient vector** of the loss function.

This is written compactly using the **nabla symbol** $\nabla$ (pronounced *“nabla”*, named after an ancient harp), which represents the gradient operator:

$$
\nabla \mathcal{L}(w_0, w_1) =
\begin{bmatrix}
\frac{\partial \mathcal{L}}{\partial w_0} \\
\frac{\partial \mathcal{L}}{\partial w_1}
\end{bmatrix}
$$

This vector points in the direction of steepest increase in loss. In **gradient descent**, we take the negative of the gradient to move in the opposite direction (steepest decent), toward the minimum.

| Symbol | Name | Meaning |
|----|----|----|
| $\mathcal{L}$ | Script L | The loss function |
| $\partial$ | Partial | Derivative with respect to one variable (holds others constant) |
| $\nabla$ | Nabla | The gradient operator—produces a vector of partial derivatives |
:::

The gradient of a function always points in the direction of steepest *ascent.* We actually want to know the direction of the steepest **descent** (to get to the bottom of the bowl-shaped surface) hence will be most interested in the negative gradient (i.e. the exact opposite direction).

If you move in a direction other than the gradient, the loss value will either stay the same or change at a slower rate.

The illustration below demonstrates taking steps down the side of the bowl.

## The Gradient of the MSE Loss Function

In the context of the **Mean Squared Error (MSE)** loss function for simple linear regression, the **gradient** tells us how to adjust our model parameters to reduce the prediction error.

### Linear Model

We model the prediction $\hat{y}^{(i)}$ as:

$$
\hat{y}^{(i)} = w_0 + w_1 x^{(i)}
$$

### MSE Loss Function

The loss function over $n$ training examples is:

$$
\mathcal{L}(w_0, w_1) = \frac{1}{n} \sum_{i=1}^n \left( \hat{y}^{(i)} - y^{(i)} \right)^2 = \frac{1}{n} \sum_{i=1}^n \left( w_0 + w_1 x^{(i)} - y^{(i)} \right)^2
$$

### Gradient of the Loss

The **gradient** is a vector of partial derivatives with respect to each parameter:

$$
\nabla \mathcal{L}(w_0, w_1) =
\begin{bmatrix}
\frac{\partial \mathcal{L}}{\partial w_0} \\
\frac{\partial \mathcal{L}}{\partial w_1}
\end{bmatrix}
=
\frac{2}{n}
\begin{bmatrix}
\sum_{i=1}^n \left( w_0 + w_1 x^{(i)} - y^{(i)} \right) \\
\sum_{i=1}^n \left( w_0 + w_1 x^{(i)} - y^{(i)} \right) x^{(i)}
\end{bmatrix}
$$

### Interpretation

-   The first component, $\frac{\partial \mathcal{L}}{\partial w_0}$, measures how the loss changes if we nudge the **intercept** $w_0$.
-   The second component, $\frac{\partial \mathcal{L}}{\partial w_1}$, measures how the loss changes if we adjust the **slope** $w_1$.

We use this gradient in **gradient descent** to update each weight:

$$
w_j \leftarrow w_j - \alpha \cdot \frac{\partial \mathcal{L}}{\partial w_j}
$$

where $\alpha$ is the learning rate.

This iterative update rule allows us to **minimize the loss** by moving in the direction of steepest descent.

::: {.callout-tip collapse="true" collapsed="true"}
## Why are we calling this "supervised" machine learning and what other types are there?
:::

In our example, **training data**,

**machine learning algorithm**

**parameters or "weights"**

(read as y-hat, the "hat" signifies that a prediction is being made. Writing $y$ without the "hat" would mean no prediction has yet been attempted).

uch as a zestimate from Zillow

## Glossary

**Simple Linear Regression**

**parameters or "weights"**

**training data**,

**machine learning algorithm**

**inference**

**supervised machine learning**

**Epoch**

-   $w_0$ is the intercept (bias term),
-   $w_1$ is the slope (weight).

To bring this to life, let's consider a concrete where we'd like to predict the price of a home.

Let:

-   $\hat{y}$ be the predicted price of a house (in thousands of dollars),
-   $x$ be the size of the house in square feet.

Suppose we have fit a linear model to a dataset and obtained:

$$
\hat{y} = 50 + 0.2 x
$$

This means: - The base price of any house (intercept) is \$50,000. - For each additional square foot, the price increases by \$200.

### Example

For a house that is 1,000 square feet:

$$
\hat{y} = 50 + 0.2 \cdot 1000 = 250
$$

So, the model predicts a price of \$250,000 for a 1,000 square foot house.

------------------------------------------------------------------------

#### Target Variable and Input Variable

-   **Target Variable** ($y$): the outcome we are trying to predict.
-   **Input Variable** ($x$): the feature used to make the prediction.

------------------------------------------------------------------------

#### Training and Validation Sets

-   **Training set**: used to learn the model parameters.
-   **Validation set**: used to evaluate how well the model generalizes to unseen data.

------------------------------------------------------------------------

#### Model Approximation and Noise

The model approximates an unknown true function: $$
y = f^*(x) + \varepsilon
$$ where $\varepsilon$ is the irreducible error.

------------------------------------------------------------------------

#### Residuals

The residuals measure the difference between actual and predicted values: $$
e_i = y_i - \hat{y}_i
$$

------------------------------------------------------------------------

#### Loss Function (Mean Squared Error)

To measure model performance: $$
\mathcal{L}(w_0, w_1) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
$$

------------------------------------------------------------------------

#### Design Matrix

With $n$ observations, the design matrix includes a bias term: $$
\mathbf{X} = \begin{bmatrix}
1 & x_1 \\
1 & x_2 \\
\vdots & \vdots \\
1 & x_n
\end{bmatrix}
$$

------------------------------------------------------------------------

#### Closed-form Solution (Normal Equation)

We can directly compute the optimal weights: $$
\mathbf{w} = (\mathbf{X}^\top \mathbf{X})^{-1} \mathbf{X}^\top \mathbf{y}
$$

------------------------------------------------------------------------

#### Parameters and Estimation

-   **Parameters**: $w_0$, $w_1$
-   **Goal**: estimate parameters that minimize the loss function

------------------------------------------------------------------------

#### Gradient Descent

When a closed-form is not used, we apply an iterative optimization: $$
w_j \leftarrow w_j - \eta \frac{\partial \mathcal{L}}{\partial w_j}
$$

With gradients: $$
\frac{\partial \mathcal{L}}{\partial w_j} = -\frac{2}{n} \sum_{i=1}^n x_{ij}(y_i - \hat{y}_i)
$$

------------------------------------------------------------------------

#### Overfitting and Underfitting

-   **Underfitting**: model too simple to capture data patterns
-   **Overfitting**: model too complex, captures noise instead of signal
-   **Validation** helps detect these behaviors.

### Multiple Linear Regression

### Logistic Regression

### Classification

## Loss Functions

A loss function is a mathematical function that measures the difference between a model's predicted output and the true target value from a training dataset. It produces a scalar value representing the error for a single data point or the average error over a batch.

-   **Cross entropy loss**: “cross entropy” and “negative average log probability” related and often used interchangeably in practice.”

-   **Perplexity**: “Perplexity is a measure often used alongside cross entropy loss to evaluate the performance of models in tasks like language modeling. ”

## Gradient Descent

::: {.callout-tip collapse="true" collapsed="true"}
## Synonyms Across Fields

Different disciplines often use different terms for the same concepts. Here's a helpful guide:

| Concept | Machine Learning | Statistics / Econometrics |
|----|----|----|
| Single data point (e.g., a row in a spreadsheet) | **Training example** | **Observation**, **Case** |
| Input features | **Features**, **Inputs** | **Independent variables**, **Regressors**, **Covariates**, **Predictors** |
| Target output | **Label**, **Target**, **Output** | **Dependent variable**, **Response** |
| Collection of data points | **Training set**, **Training data** | **Sample**, **Dataset** |
| Parameter | **Weight** (e.g., $w_1$) | **Coefficient** (e.g., $\beta_1$) |
| Model prediction | $\hat{y}$ | **Fitted value**, **Predicted value** |
| Loss function | **Loss** | **Objective function**, **Criterion function** |
| Learn model parameters | **Training**, **Fitting** | **Estimation** |

Understanding these parallels can make it much easier to bridge terminology between fields as you move through the course.
:::

### Supervised Learning Use Cases

**Supervised Learning (Regression) Use Cases**

| Use Case | Sample Inputs | Model Output Description | What ML Question is Being Answered? | What Business Question is Being Answered? | Example Algorithm(s) |
|----|----|----|----|----|----|
| Price Prediction | Property size, location, features | Numeric price | What is the expected price of this item? | How should I price products to stay competitive and profitable? | Linear Regression, CatBoost |
| Demand Forecasting | Historical sales, promotions, holidays | Predicted sales volume | What will sales be next week/month? | How can I manage inventory or staffing to meet demand? | Linear Regression, LSTM |
| Medical Risk Score | Patient vitals, history | Risk score (e.g., probability of event) | How likely is a medical event to occur? | How should I prioritize preventive care for patients? | Random Forest, Ridge Reg. |
| Revenue Forecasting | Past financials, seasonality | Revenue over next time period | How much revenue will we make? | How can I allocate budgets or set growth targets? | Time Series Models, XGBoost |
| Energy Usage Estimation | Time of day, weather, appliance use | Predicted energy consumption | How much energy will be used in this period? | How should I manage power supply or optimize grid efficiency? | Linear Regression, SVR |

**Supervised Learning (Classification) Use Cases**

| Use Case | Sample Inputs | Model Output Description | What ML Question is Being Answered? | What Business Question is Being Answered? | Example Algorithm(s) |
|----|----|----|----|----|----|
| Email Spam Detection | Email content, sender info, subject line | Binary label: spam or not spam | Is this email spam? | How can I prevent unwanted emails from reaching users’ inboxes? | Logistic Regression, SVM |
| Credit Risk Scoring | Income, credit history, employment data | Risk category (e.g., low/medium/high) | Will this applicant default? | Should I approve this loan, and at what interest rate? | Decision Tree, XGBoost |
| Image Classification | Pixel values from an image | Object class label (e.g., “cat”, “dog”) | What object is in this image? | How can I organize photos or automate product tagging? | CNNs, ResNet |
| Sentiment Analysis | Review text, social media posts | Sentiment label (positive/negative) | What sentiment is being expressed? | What is the public opinion about my product or brand? | Naive Bayes, BERT |
| Disease Diagnosis | Symptoms, test results, demographics | Disease class (e.g., flu, COVID, none) | What condition does this patient likely have? | How can I assist doctors in making accurate and timely diagnoses? | Random Forest, Neural Nets |

## Unsupervised Learning

### Unsupervised Learning Use Cases

| Use Case | Sample Inputs | Model Output Description | What ML Question is Being Answered? | What Business Question is Being Answered? | Example Algorithm(s) |
|----|----|----|----|----|----|
| Customer Segmentation | Age, income, purchase history | Cluster/group labels for each customer | What types of customers exist in my data? | How can I tailor marketing strategies to different customer types? | K-means, DBSCAN |
| Topic Modeling | Articles or documents | Topics with keywords per document | What topics are being discussed? | What content themes resonate most with my audience or market? | LDA, NMF |
| Anomaly Detection | Transaction logs, sensor data | Anomaly score or binary flag | Which data points are unusual? | Are there fraudulent transactions or system failures I need to act on? | Isolation Forest, Autoencoder |
| Dimensionality Reduction | High-dimensional features (e.g., pixels) | 2D or 3D projections for analysis or visualization | How can I reduce feature space while preserving info? | How can I visualize or simplify complex data for human analysis or modeling? | PCA, t-SNE, UMAP |
| Market Basket Analysis | Sets of purchased items | Association rules (A & B → C) | What items co-occur frequently in purchases? | Which product bundles or cross-sell offers should I promote? | Apriori, FP-Growth |
| Word Embedding | Text corpus | Word vectors capturing semantic similarity | What are the contextual relationships between words? | How can I build a smarter search engine or chatbot that understands language context? | Word2Vec, GloVe |
| Image Compression | Raw pixel arrays | Compressed version of the image | How can I represent this image with fewer features? | How can I reduce storage or transmission costs for image data? | Autoencoders |

## Reinforcement Learning

### Reinforcement Learning Use Cases

| Use Case | Sample Inputs | Model Output Description | What ML Question is Being Answered? | What Business Question is Being Answered? | Example Algorithm(s) |
|----|----|----|----|----|----|
| Game Playing | Game state (e.g., board, score) | Action to take | What should I do to win the game? | How can I build an AI that outperforms humans or creates adaptive gameplay? | Q-learning, DQN |
| Robotics & Control | Sensor data (angles, velocities, etc.) | Movement or control signals | How should the agent move next to reach a goal? | How can I automate physical tasks like picking, sorting, or navigating? | PPO, SAC, DDPG |
| Autonomous Vehicles | Sensor input (camera, LIDAR, speed, GPS) | Driving action | What’s the optimal next driving move? | How can I develop a safe and efficient self-driving vehicle system? | Deep RL + sensor fusion |
| Recommendation Systems | User history, preferences, session behavior | Recommended item | What should I recommend next? | How can I increase user retention, engagement, or sales? | Contextual Bandits, RL |
| Portfolio Management | Financial indicators, stock prices | Asset allocation decision | How should I invest to maximize return? | How can I build an automated trading or portfolio optimization system? | Actor-Critic methods |
| Personalized Education | Student progress and quiz results | Next learning step | What lesson or content should come next? | How can I boost student outcomes by personalizing learning pathways? | Multi-armed bandits |
| Healthcare Treatment | Patient history and vitals | Treatment or intervention strategy | What care plan maximizes long-term patient health? | How can I optimize healthcare outcomes while reducing costs and readmissions? | Off-policy RL, POMDPs |

## Machine Learning

Supervised Learning: "Here’s the question and the right answer."\
Unsupervised Learning: "Here is some data, can you find patterns and/or organize it in a meaningful way?"\
Reinforcement Learning: "You’re an agent playing a, figure out the best strategy through trial and error, using only points (rewards) as feedback."

"During training, a machine learning algorithm processes a dataset and chooses the function that best matches the patterns in the data."

supervised, unsupervised, and reinforcement.

## Supervised Learning

Supervised learning is the most widely used type of machine learning and significantly overlaps with the methodologies of other quantitative fields, such as statistics and econometrics.

Supervised learning gets its name from the fact that the input data set has examples of both inputs and outputs.

The outputs are called labels, hence you will sometime hear the term "labeled dataset."

-   **logistic (sigmoid) function**:

-   **Softmax**: